{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:46:38.487288: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-11 10:46:38.488772: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model = load_model('Model/cat_dog.h5', compile=False, custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "\n",
    "# reloaded = tf.keras.experimental.load_from_saved_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat\\n', 'Dog']\n"
     ]
    }
   ],
   "source": [
    "# Load the labels\n",
    "class_names = open('Model/catdoglabel.txt', 'r').readlines()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 150, 150, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/inputs.py:256: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/outputs.py:196: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x293834580>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:50:21.580259: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-11 10:50:21.680039: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 551ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/routes.py\", line 284, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/blocks.py\", line 950, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator)\n",
      "  File \"/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/blocks.py\", line 792, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/fd/1mv0d7g16sx55cwb0hmjv94c0000gn/T/ipykernel_59159/3832206514.py\", line 5, in predict_input_image\n",
      "    return {class_names[i]: float(prediction[i]) for i in range(38)}\n",
      "  File \"/var/folders/fd/1mv0d7g16sx55cwb0hmjv94c0000gn/T/ipykernel_59159/3832206514.py\", line 5, in <dictcomp>\n",
      "    return {class_names[i]: float(prediction[i]) for i in range(38)}\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n"
     ]
    }
   ],
   "source": [
    "def predict_input_image(img):\n",
    "    img_4d=img.reshape(-1,150,150,3)\n",
    "    img_4d=img_4d/255.0\n",
    "    prediction=model.predict(img_4d)[0]\n",
    "    return {class_names[i]: float(prediction[i]) for i in range(38)}\n",
    "    \n",
    "image = gr.inputs.Image(shape=(150,150))\n",
    "label = gr.outputs.Label(num_top_classes=2)\n",
    "interface = gr.Interface(fn=predict_input_image, inputs=image, outputs=label,interpretation='default')\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('Old-ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc483c805e62f4053278fc8cfbbed924f4427ee7b97e298d40f6fe878a546fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
