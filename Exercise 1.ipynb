{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Web App to Recognize Handwritten Digits â€” in 19 Lines of Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://medium.com/swlh/a-gui-to-recognize-handwritten-digits-in-19-lines-of-python-fda715e525d0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Oct 28, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio\n",
    "# !pip install tensorflow-macos\n",
    "# !pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.0, \n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 13:44:35.246946: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-31 13:44:35.247985: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 13:44:35.717230: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14/1875 [..............................] - ETA: 7s - loss: 1.9780 - accuracy: 0.3728  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 13:44:35.974231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 13:44:43.366322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2637 - accuracy: 0.9241 - val_loss: 0.1417 - val_accuracy: 0.9584\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1156 - accuracy: 0.9655 - val_loss: 0.1042 - val_accuracy: 0.9686\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0778 - accuracy: 0.9765 - val_loss: 0.0872 - val_accuracy: 0.9729\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0588 - accuracy: 0.9821 - val_loss: 0.0676 - val_accuracy: 0.9797\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.0744 - val_accuracy: 0.9779\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0791 - val_accuracy: 0.9762\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.0692 - val_accuracy: 0.9784\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0717 - val_accuracy: 0.9791\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0766 - val_accuracy: 0.9788\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0894 - val_accuracy: 0.9770\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0843 - val_accuracy: 0.9792\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0781 - val_accuracy: 0.9796\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0839 - val_accuracy: 0.9800\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0913 - val_accuracy: 0.9802\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0859 - val_accuracy: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29d0bd160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/outputs.py:196: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/gluthfi/opt/miniconda3/envs/Old-ML/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hint: Set streaming=True for Sketchpad component to use live streaming.\n",
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x28169afa0>, 'http://127.0.0.1:7869/', None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(input):\n",
    "    prediction = model.predict(input.reshape(1, 28, 28)).tolist()[0]\n",
    "    return {str(i): prediction[i] for i in range(10)}\n",
    "\n",
    "label = gr.outputs.Label(num_top_classes=3)\n",
    "interface = gr.Interface(fn=classify, inputs=\"sketchpad\", outputs=label, \n",
    "live=True)\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('Old-ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc483c805e62f4053278fc8cfbbed924f4427ee7b97e298d40f6fe878a546fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
